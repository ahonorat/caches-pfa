\section{Les différentes politiques configurables}
\label{politiques}

Plusieurs aspects de l'architecture sont configurables. Selon l'option il s'agit de choisir la configuration parmi une liste prédéterminée, ou bien de la configurer soi-même. 

\subsection{Politique de gestion des threads (par défaut)}

Le simulateur s'utilise avec une trace par c\oe ur, l'utilisateur a la possibilité de gérer l'entrelacement de ces différentes traces. Il peut par exemple choisir le nombre d'instructions à exécuter dans chaque trace, avant de passer à la suivante. Par défaut, si l'utilisateur ne configure pas ce fichier (écrit en \texttt{lua}), le simulateur choisit d'exécuter une instruction de chaque trace à la suite. Si l'une des traces est plus courte que les autres, le c\oe ur sur lequel elle était exécutée n'est plus utilisé. Et l'instruction suivante est celle de la trace immédiatement après celle qui est terminée.

\subsection{Politiques de remplacement des lignes de cache}

Lorsqu'un cache est plein, s'il a besoin de stocker une nouvelle ligne, il va devoir un supprimer une autre. Trois façons de sélectionner la ligne à supprimer sont implémentées dans le simulateur. 

\paragraph{FIFO.}La première possibilité est de  supprimer la ligne la plus ancienne du cache ce qui correspond à la formule : ``First In, First Out''.

\paragraph{LRU.}Une meilleure approche consiste à supprimer la ligne qui n'a pas été utilisée depuis le plus longtemps : ``Least Recently Used''. Cette approche permet de garder à proximité du c\oe ur les lignes qu'ils utilisent le plus, et fait donc gagner en rapidité.

\paragraph{LFU.}La méthode ``Least Frequently Used'' se base quant à elle sur les fréquences d'utilisation de chaque ligne ; il est donc préférable de l'appliquer dans des caches où les lignes restent suffisamment longtemps pour différencier ces fréquences, pas dans des caches L1 par exemple. 

\subsection{Politiques de cohérence}
\label{coher}

Les données étant souvent partagées par plusieurs caches, si l'un des caches modifie une donnée partagée, il doit prévenir les autres pour qu'ils invalident leur version de la ligne contenant la donnée concernée. Une politique de cohérence est alors nécessaire dès que certains caches sont en \emph{write-back} ; c'est-à-dire qu'il n'écrit ses données modifiées dans la mémoire de niveau supérieur que lorsque les lignes les contenant doivent être vidées. Le simulateur impose ici à l'utilisateur que tous les caches sont en \emph{write-back}. Plusieurs moyens d'effectuer la cohérence (i.e. de gérer le partage d'une donnée entre différents caches) sont implémentés dans le simulateur. Notons que ces différents moyens de cohérence n'ont pas d'influence sur le nombre de \emph{cache-misses/hits}, mais uniquement sur le nombre de \emph{broadcasts} que chaque c\oe ur sera obligé de faire, ce qui est aussi une source de ralentissement lors de l'exécution d'un programme. 

\paragraph{MSI.} Ce protocole définit trois états possibles pour chaque ligne du cache. Cest trois états sont \emph{Modified}, \emph{Shared} et \emph{Invalid}.

\paragraph{MESI.} Le protocole \texttt{MESI} se base sur \texttt{MSI} en rajoutant l'état \emph{Exclusive}. Ce nouvel état permet de gagner du temps lorsque l'unique propriétaire de la ligne (par conséquent dans l'état \emph{Exclusive} souhaite la modifier : il n'a pas besoin d'effectuer de broadcast puisqu'il est le seul à la contenir.

\paragraph{MOESI.} L'état \emph{Owned} rajouté par le protocole \texttt{MOESI} au protocole \texttt{MESI} permet quant à lui un gain de temps moins significatif. En effet lorsqu'une ligne passe dans l'état \emph{Owned}, c'est parce qu'un autre cache a récupéré cette ligne. Par conséquent le cache possédant une ligne \emph{Owned} n'effectue pas de \emph{write-back}, c'est le cache qui a récupéré cette ligne qui le fera à sa place. Cela limite ainsi le nombre de \emph{write-back}.

\subsection{Politiques plus globales}
\label{global}

\indent Il existe trois types de caches: \\
\begin{itemize}
\item Inclusif: contient les donn\'ees des caches en dessous dans la hi\'erarchie.
\item Exclusif: ne contient pas les donn\'ees des caches en dessous dans la hi\'erarchie.
\item Non Inclusif: peut contenir les donn\'ees des caches en dessous dans la hi\'erarchie. \\
\end{itemize}

\indent Le cache de dernier niveau -- LLC: Last Level Cache -- est fondamental dans la gestion hi\'erarchique de la coh\'erence. Avec un LLC inclusif, lorsqu'un L2 fait un Miss, il demande la donn\'ee au L3 qui fait un Hit ou un Miss. En cas de Miss, aucun autre cache de la hi\'erarchie ne peut poss\`eder la donn\'ee. A contrario, avec un LLC exclusif, l'ensemble de la hi\'erachie doit \^etre parcourue avant de demander la donn\'ee \'a la m\'emoire principale. \\

\indent Concr\`etement, les solutions pour \'eviter ce parcours de la hi\'erarchie sont l'utilisation du snooping ou la pr\'esence d'un directory manager, comprenant l'ensemble des \'etiquettes pr\'esentes dans la hi\'erarchie. D'autres solutions sont envisageables, mais le design du fonctionnement de la hi\'erarchie est plus d\'elicat. Nous proposons donc de mettre en place ces trois cas de figure et d'exploiter d'autres solutions si le temps nous le permet. A noter que pour profiter pleinemement des avantages du snooping d'un point de vue coh\'erence, il doit \^etre possible pour tous les niveaux de la hi\'erarchie.
