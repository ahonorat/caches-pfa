\section{Les différentes politiques configurables}
\label{politiques}

Plusieurs aspects de l'architecture sont configurables. Selon l'option il s'agit de choisir la configuration parmi une liste prédéterminée, ou bien de la configurer soi-même. 

\subsection{Politique de gestion des threads (par défaut)}

Le simulateur s'utilise avec une trace par c\oe ur, l'utilisateur a la possibilité de gérer l'entrelacement de ces différentes traces. Il peut par exemple choisir le nombre d'instructions à exécuter dans chaque trace, avant de passer à la suivante. Par défaut, si l'utilisateur ne configure pas ce fichier (écrit en \texttt{lua}), le simulateur choisit d'exécuter une instruction de chaque trace à la suite. Si l'une des traces est plus courte que les autres, le c\oe ur sur lequel elle était exécutée n'est plus utilisé. Et l'instruction suivante est celle de la trace immédiatement après celle qui est terminée.

\subsection{Politiques de remplacement des lignes de cache}

Lorsqu'un cache est plein, s'il a besoin de stocker une nouvelle ligne, il va devoir en supprimer une autre. Trois façons de sélectionner la ligne à supprimer sont implémentées dans le simulateur. 

\paragraph{FIFO.}La première possibilité est de  supprimer la ligne la plus ancienne du cache ce qui correspond à la formule : ``First In, First Out''.

\paragraph{LRU.}Une meilleure approche consiste à supprimer la ligne qui n'a pas été utilisée depuis le plus longtemps : ``Least Recently Used''. Cette approche permet de garder à proximité du c\oe ur les lignes qu'ils utilisent le plus, et fait donc gagner en rapidité.

\paragraph{LFU.}La méthode ``Least Frequently Used'' se base quant à elle sur les fréquences d'utilisation de chaque ligne ; il est donc préférable de l'appliquer dans des caches où les lignes restent suffisamment longtemps pour différencier ces fréquences, pas dans des caches L1 par exemple. 

\subsection{Politiques de cohérence}
\label{coher}

Les données étant souvent partagées par plusieurs caches, si l'un des caches modifie une donnée partagée, il doit prévenir les autres pour qu'ils invalident leur version de la ligne contenant la donnée concernée. Une politique de cohérence est alors nécessaire et plusieurs sont implémentées dans le simulateur. Notons que ces différents moyens de cohérence n'ont pas d'influence sur le nombre de \emph{cache-misses/hits}, mais uniquement sur le nombre de \emph{broadcasts} que chaque c\oe ur sera obligé de faire, ce qui est aussi une source de ralentissement lors de l'exécution d'un programme. Par ailleurs le simulateur impose ici à l'utilisateur que tous les caches sont en \emph{write-back}\footnote{Un cache en \emph{write-back} n'écrit ses données modifiées dans la mémoire de niveau supérieur que lorsque les lignes les contenant doivent être vidées. Cela s'oppose à la méthode \emph{write-through} qui recopie les données directement.}.

\paragraph{MSI.} Ce protocole définit trois états possibles pour chaque ligne du cache. Cest trois états sont \emph{Modified}, \emph{Shared} et \emph{Invalid}.

\paragraph{MESI.} Le protocole \texttt{MESI} se base sur \texttt{MSI} en rajoutant l'état \emph{Exclusive}. Ce nouvel état permet de gagner du temps lorsque l'unique propriétaire de la ligne (par conséquent dans l'état \emph{Exclusive} souhaite la modifier : il n'a pas besoin d'effectuer de broadcast puisqu'il est le seul à la contenir.

\paragraph{MOESI.} L'état \emph{Owned} rajouté par le protocole \texttt{MOESI} au protocole \texttt{MESI} permet quant à lui un gain de temps moins significatif. En effet lorsqu'une ligne passe dans l'état \emph{Owned}, c'est parce qu'un autre cache a récupéré cette ligne. Par conséquent le cache possédant une ligne \emph{Owned} n'effectue pas de \emph{write-back}, c'est le cache qui a récupéré cette ligne qui le fera à sa place. Cela limite ainsi le nombre de \emph{write-back}.

\subsection{Types d'inclusivité des caches}
\label{global}

Il existe trois types de caches:
\begin{itemize}
\item Inclusif, contient les données des caches en dessous dans la hiérarchie ;
\item Exclusif, ne contient pas les données des caches en dessous dans la hiérarchie ;
\item Non Inclusif, peut contenir les données des caches en dessous dans la hiérarchie.\\
\end{itemize}

Le cache de dernier niveau -- LLC: Last Level Cache -- est fondamental dans la gestion hiérarchique de la cohérence. Avec un LLC inclusif, lorsqu'un L2 fait un Miss, il demande la donnée au L3 qui fait un Hit ou un Miss. En cas de Miss, aucun autre cache de la hiérarchie ne peut posséder la donnée. A contrario, avec un LLC exclusif, l'ensemble de la hiérachie doit être parcourue avant de demander la donnée à la mémoire principale.


Concrètement, les solutions pour éviter ce parcours de la hiérarchie sont l'utilisation du \emph{snooping} ou la présence d'un \emph{directory manager}, comprenant l'ensemble des étiquettes présentes dans la hiérarchie. D'autres solutions sont envisageables, mais le design du fonctionnement de la hiérarchie est plus délicat. Nous proposons donc de mettre en place ces trois cas de figure et d'exploiter d'autres solutions si le temps nous le permet. \`A noter que pour profiter pleinemement des avantages du snooping d'un point de vue cohérence, il doit être possible pour tous les niveaux de la hiérarchie.
